{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>드라마</th>\n",
       "      <th>날짜</th>\n",
       "      <th>회차</th>\n",
       "      <th>요일</th>\n",
       "      <th>배우</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPI증감률</th>\n",
       "      <th>경제성장률</th>\n",
       "      <th>실업률</th>\n",
       "      <th>미세먼지</th>\n",
       "      <th>연출자</th>\n",
       "      <th>작가</th>\n",
       "      <th>특이사항</th>\n",
       "      <th>시청률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)</td>\n",
       "      <td>2012.02.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>96.436</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)</td>\n",
       "      <td>2012.02.26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>96.436</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)</td>\n",
       "      <td>2012.03.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>96.436</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)</td>\n",
       "      <td>2012.03.04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>96.436</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)</td>\n",
       "      <td>2012.03.10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>96.436</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  드라마          날짜  회차  요일  배우     CPI  CPI증감률  \\\n",
       "0  넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)  2012.02.25   1   0  75  96.436     2.9   \n",
       "1  넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)  2012.02.26   2   1  75  96.436     2.9   \n",
       "2  넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)  2012.03.03   3   0  75  96.436     2.9   \n",
       "3  넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)  2012.03.04   4   1  75  96.436     2.9   \n",
       "4  넝쿨째 굴러온 당신 (2012.02.25~2012.09.09)  2012.03.10   5   0  75  96.436     2.9   \n",
       "\n",
       "   경제성장률  실업률  미세먼지  연출자  작가  특이사항   시청률  \n",
       "0    0.7  4.2    47    5  10     0  22.3  \n",
       "1    0.7  4.2    47    5  10     0  28.9  \n",
       "2    0.7  3.7    43    5  10     0  25.7  \n",
       "3    0.7  3.7    43    5  10     0  29.9  \n",
       "4    0.7  3.7    43    5  10     0  26.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "\n",
    "path = os.getcwd()\n",
    "drama = pd.read_csv(path+'/drama.csv',sep=',')\n",
    "drama.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.9\n",
       "1      2.9\n",
       "2      2.9\n",
       "3      2.9\n",
       "4      2.9\n",
       "      ... \n",
       "779   -0.3\n",
       "780   -0.3\n",
       "781   -0.3\n",
       "782   -0.3\n",
       "783   -0.3\n",
       "Name: CPI증감률, Length: 784, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drama.pop('드라마')\n",
    "drama.pop('날짜')\n",
    "drama.pop('CPI')\n",
    "drama.pop('CPI증감률')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drama.rename(columns={'회차': 'Episode', '요일': 'Day', '배우': 'Actor', '경제성장률': 'GDP' , '실업률' : 'Job',  '미세먼지': 'Dust',\n",
    "                     '연출자': 'Director', '작가': 'Author', '특이사항': 'Exception', '시청률': 'Rate'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actor</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Job</th>\n",
       "      <th>Dust</th>\n",
       "      <th>Director</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>779</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actor  GDP  Job  Dust  Director  Author\n",
       "0       75  0.7  4.2    47         5      10\n",
       "1       75  0.7  4.2    47         5      10\n",
       "2       75  0.7  3.7    43         5      10\n",
       "3       75  0.7  3.7    43         5      10\n",
       "4       75  0.7  3.7    43         5      10\n",
       "..     ...  ...  ...   ...       ...     ...\n",
       "779     63  1.0  3.0    24         3       6\n",
       "780     63  1.0  3.0    24         3       6\n",
       "781     63  1.0  3.0    24         3       6\n",
       "782     63  1.0  3.0    24         3       6\n",
       "783     63  1.0  3.0    24         3       6\n",
       "\n",
       "[784 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(drama.shape)\n",
    "drama.head()\n",
    "drama.iloc[:,2:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 9), (784, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(drama.iloc[:,2:-2])\n",
    "X_scaled = scaler.transform(drama.iloc[:,2:-2])\n",
    "np.mean(X_scaled), np.std(X_scaled)\n",
    "drama.iloc[:,2:-2] = X_scaled\n",
    "\n",
    "X = drama.values[:,:-1]\n",
    "y = drama.iloc[:,-1:].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = 29.29\n",
    "y_label = np.zeros(784)\n",
    "\n",
    "for i in range(784):\n",
    "    if y[i] > mean :\n",
    "        y_label[i] = 1 # 흥행 성공\n",
    "        \n",
    "y_label.sum() # 저랑 숫자가 달라서 여쭤봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 9) (196, 9) (588,) (196,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_label, test_size = 0.25, random_state = 777)\n",
    "\n",
    "print(\n",
    "    \n",
    "    X_train.shape,\n",
    "    X_test.shape,\n",
    "    y_train.shape,\n",
    "    y_test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR Confusion Matrix:\n",
      " [[100  11]\n",
      " [ 12  73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90       111\n",
      "         1.0       0.87      0.86      0.86        85\n",
      "\n",
      "    accuracy                           0.88       196\n",
      "   macro avg       0.88      0.88      0.88       196\n",
      "weighted avg       0.88      0.88      0.88       196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smsm8898/miniconda3/envs/tf/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "expected = y_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print('\\nLR Confusion Matrix:\\n',\n",
    "     metrics.confusion_matrix(expected,predicted))\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512301\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  588\n",
      "Model:                          Logit   Df Residuals:                      579\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Sat, 26 Oct 2019   Pseudo R-squ.:                  0.2553\n",
      "Time:                        19:18:13   Log-Likelihood:                -301.23\n",
      "converged:                       True   LL-Null:                       -404.50\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.669e-40\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0034      0.005      0.737      0.461      -0.006       0.012\n",
      "x2             0.6680      0.185      3.610      0.000       0.305       1.031\n",
      "x3             1.9513      0.439      4.446      0.000       1.091       2.812\n",
      "x4             0.0375      0.112      0.335      0.737      -0.182       0.257\n",
      "x5            -0.5557      0.151     -3.675      0.000      -0.852      -0.259\n",
      "x6             0.2146      0.106      2.020      0.043       0.006       0.423\n",
      "x7            -0.3773      0.406     -0.928      0.353      -1.174       0.419\n",
      "x8            -0.5956      0.436     -1.367      0.172      -1.450       0.258\n",
      "x9            -1.5475      0.458     -3.381      0.001      -2.444      -0.650\n",
      "==============================================================================\n",
      "####x1:num, x2:day, x3:actor, x4:GDP, x5:job, x6:dust, x7:director, x8:author, x9:spe####\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "# logit = sm.Logit(y_train.astype(np.float), X_train.astype(np.float))\n",
    "\n",
    "result = logit.fit()\n",
    "\n",
    "print(result.summary())\n",
    "print(\"####x1:num, x2:day, x3:actor, x4:GDP, x5:job, x6:dust, x7:director, x8:author, x9:spe####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF Confusion Matrix:\n",
      " [[104   7]\n",
      " [  9  76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       111\n",
      "         1.0       0.92      0.89      0.90        85\n",
      "\n",
      "    accuracy                           0.92       196\n",
      "   macro avg       0.92      0.92      0.92       196\n",
      "weighted avg       0.92      0.92      0.92       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    n_estimators = 50, # 약한 학습기의 개수\n",
    "    max_depth = 5, # 모델의 최대 깊이\n",
    "    criterion = 'gini' # 결정 트리 알고리즘\n",
    ")\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "expected = y_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print('\\nRF Confusion Matrix:\\n',\n",
    "     metrics.confusion_matrix(expected,predicted))\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 중요도 : \n",
      "[0.32290664 0.14513033 0.16821986 0.02555861 0.04018303 0.06900925\n",
      " 0.08789157 0.13662959 0.00447113]\n",
      "####x1:num, x2:day, x3:actor, x4:GDP, x5:job, x6:dust, x7:director, x8:author, x9:spe####\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 특성 중요도\n",
    "\n",
    "print(\"특성 중요도 : \\n{}\".format(classifier.feature_importances_))\n",
    "\n",
    "\n",
    "\n",
    "# 특성 중요도 시각화 하기\n",
    "\n",
    "def plot_feature_importances_drama(classifier):\n",
    "\n",
    "    n_features = drama.shape[1]-1\n",
    "\n",
    "    plt.barh(range(n_features), classifier.feature_importances_, align='center')\n",
    "\n",
    "    plt.yticks(np.arange(n_features), drama.columns)\n",
    "\n",
    "    plt.xlabel(\"feature importances\")\n",
    "\n",
    "    plt.ylabel(\"features\")\n",
    "\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plt.show()\n",
    "print(\"####x1:num, x2:day, x3:actor, x4:GDP, x5:job, x6:dust, x7:director, x8:author, x9:spe####\")\n",
    "plot_feature_importances_drama(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Confusion Matrix:\n",
      " [[104   7]\n",
      " [ 12  73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92       111\n",
      "         1.0       0.91      0.86      0.88        85\n",
      "\n",
      "    accuracy                           0.90       196\n",
      "   macro avg       0.90      0.90      0.90       196\n",
      "weighted avg       0.90      0.90      0.90       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(\n",
    "    kernel='linear'\n",
    "#     C=1, # 페널티 파라미터 - 어느 정도 오류 분류를 허용\n",
    "#     gamma = 0.001 # 큰 값이 설정되면 복잡한 분리 곡면을 지정\n",
    ")\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "expected = y_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "# 성능평가\n",
    "print('\\nSVC Confusion Matrix:\\n',\n",
    "     metrics.confusion_matrix(expected, predicted))\n",
    "print(metrics.classification_report(expected,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficient:\n",
      " [ 0.01503176  0.33454687  0.33391867 -0.0004782  -0.00173324  0.07479977\n",
      " -0.0516248  -0.03716395 -0.16731111]\n",
      "\n",
      "x1:Episode, x2:Day, x3:Actor, x4:GDP, x5:Job, x6:Dust, x7:Director, x8:Author, x9:Exception\n",
      "\n",
      "\n",
      "Intercept:\n",
      " -0.11387114788899494\n",
      "\n",
      "R2-Score\n",
      ": 0.5695619504603149\n",
      "\n",
      "MSE\n",
      ": [0.10571593]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('\\nCoefficient:\\n',model.coef_)\n",
    "print(\"\\nx1:Episode, x2:Day, x3:Actor, x4:GDP, x5:Job, x6:Dust, x7:Director, x8:Author, x9:Exception\\n\")\n",
    "print('\\nIntercept:\\n',model.intercept_)\n",
    "print('\\nR2-Score\\n:', model.score(X_test,y_test))\n",
    "print('\\nMSE\\n:', mean_squared_error(y_test, y_pred, multioutput='raw_values'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================\n",
    "LR Accuracy: 0.89\n",
    "LR F1 : 0.87\n",
    "Logistic Regression에서는 \n",
    "x3:Actor, x1:Episode, x2:Day, x6:Dust 의 coef가 상당가 매우 크고 p-value가 낮음\n",
    "\n",
    "RF Accuracy: 0.91\n",
    "RF F1 : 0.90\n",
    "Random Forest는 \n",
    "x1:Episode, x3:Actor, x2:Day, x8:Author 순으로 Feature Importance가 나옴\n",
    "\n",
    "=> 상위 3개는 같고 4번째는 다름\n",
    "\n",
    "어떤 점에서 비슷한 모양이 나올까 궁금해서 linear SVC을 사용해봄\n",
    "\n",
    "SVC Accuracy : 0.90\n",
    "SVC F1 : 0.88\n",
    "=> linear kernel을 했을 때, accuracy가 상당히 높은거로 봐서 linear한 관계가 있음을 알 수 있음\n",
    "\n",
    "좀 더 확실하게 확정짓고 싶어서 Linear Regression 실행\n",
    "x3:Actor x1:Episode x2:Day x6:Dust의 순서로 coef의 크기가 큼 => 시청률과 각 변수는 확실하게 선형적인 관계가 있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[TF]",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
